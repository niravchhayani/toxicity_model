# toxicity_model
1st attempt to create a simple web API where use can give an input in the text format and using my own machine learning model, predict the toxicity of the text.
Toxicity in text is defined by rude, disrespectful, or unresaonable comments that is likely to make people leave a discussion.

# Gettign Started
A very unpleasant, aggressive, filled with hatred comments or otherwise very likely to make a user leave a discussion or give up sharing their point of view. I tired to make model receptive to use of curse words in positive way. However, it must be mention in the documentation that this is very simple and initial level model for the beginner. The dataset used to train model is also having curse words in the abstract format, such as use of special characters like * # @ ! etc. So, it has sensitivity to the toxicity in the form of abbreviations.

Follow this document to download, use and understand the toxicity_model.

## Prerequisites
'''
Python 3.0 or above
Disk Space 1 GB or more
'''
